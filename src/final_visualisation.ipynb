{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the data\n",
    "First step is to scrape data from www.datacenters.com\n",
    "There are 85 pages, each with many data centres listed.\n",
    "So, iterate through each page, and then iterate through each data centre and retrieve its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://www.datacenters.com/locations'  # base URL of initial page\n",
    "\n",
    "# Function to get the HTML content of a page\n",
    "def get_html(url: str) -> str | None:\n",
    "    '''\n",
    "    Get the HTML content of a page.\n",
    "\n",
    "    Args:\n",
    "        url (str): text URL.\n",
    "\n",
    "    Returns:\n",
    "        str | None: text content of page, if available.\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:  # successful get\n",
    "        return response.text\n",
    "    return None\n",
    "\n",
    "def get_data_center_links(page_number: int) -> list:\n",
    "    '''\n",
    "    Parse the initial page and extract links to individual data centres.\n",
    "\n",
    "    Args:\n",
    "        page_number (int): number between 1 and 86 representing the current page.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of all the data centres on this page.\n",
    "    '''\n",
    "    url = f'{base_url}?page={page_number}'\n",
    "    html = get_html(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = []\n",
    "    grid = soup.find_all('div', class_='LocationsIndex__tiles__Sc6sW')  # find the grid list of data centres\n",
    "    for grid_item in grid[0].find_all('div', class_='LocationTile__location__tZKRS'):  # iterate through and extract the individual hrefs\n",
    "        a_tag = grid_item.find('a')\n",
    "        if a_tag:\n",
    "            links.append(a_tag['href'])\n",
    "    return links\n",
    "\n",
    "def extract_data_center_info(url: str) -> dict:\n",
    "    '''\n",
    "    Extract data from an individual data centre page.\n",
    "\n",
    "    Args:\n",
    "        url (str): text URL of individual data centre page.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary containing all extracted data.\n",
    "    '''\n",
    "    html = get_html(url)\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    except:\n",
    "        print('Page not found! Skipping!')\n",
    "    try:\n",
    "        info = soup.find('div', class_='LocationShow__sidebar__Pqjuu') # try to locate the main block of information on the page\n",
    "    except:\n",
    "        return {}\n",
    "    try:\n",
    "        name = info.find('a', class_='LocationShowSidebar__sidebarProviderLink__CRcRB').text.lstrip('View ')  # extract the owning company name\n",
    "    except:\n",
    "        name = np.nan\n",
    "    try:\n",
    "        location = info.find('span', class_='LocationShowSidebar__sidebarAddress__AZdxu').text.split(',')  # extract the address\n",
    "    except:\n",
    "        location = np.nan\n",
    "\n",
    "    if location:  # if the address was successfully extracted, then try splitting it into components\n",
    "        try:\n",
    "            country = location[-1]\n",
    "        except IndexError:\n",
    "            country = np.nan\n",
    "        try:\n",
    "            city = location[-2]\n",
    "        except IndexError:\n",
    "            city = np.nan\n",
    "        try:\n",
    "            town = location[-3]\n",
    "        except IndexError:\n",
    "            town = np.nan\n",
    "        try:\n",
    "            address = location[-4]\n",
    "        except IndexError:\n",
    "            address = np.nan\n",
    "\n",
    "    data_dict = {  # store current data in a dictionary\n",
    "        'name': name,\n",
    "        'country': country,\n",
    "        'city': city,\n",
    "        'town': town,\n",
    "        'address': address,\n",
    "        'total space (sqft)': np.nan,\n",
    "        'colocation space (sqft)': np.nan,\n",
    "        'total power (MW)': np.nan,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        stats = info.find('div', class_='LocationShowSidebar__sidebarStats__OxlOT')  # extract statistics block\n",
    "    except:\n",
    "        return data_dict\n",
    "    for i, stat in enumerate(stats.find_all('div', class_='LocationShowSidebarStat__statContainer__LPgsu')):  # iterate through individual stats\n",
    "        if i < 3:  # only interested in the first three\n",
    "            stat_text = stat.find_all('div')[-1].text\n",
    "            stat_text = stat_text.split(' ')\n",
    "            try:\n",
    "                data_dict[f'{stat_text[2]} {stat_text[3]} ({stat_text[1]})'] = f'{stat_text[0]}'  # extract formatted stat, i.e. total power (MW) = 1\n",
    "            except IndexError:\n",
    "                pass  # missing data for this stat\n",
    "    return data_dict\n",
    "\n",
    "def main() -> None:\n",
    "    '''\n",
    "    Main script to collect all data and output to csv.\n",
    "    '''\n",
    "    data_centers = []\n",
    "    for page in range(1, 86):  # there are 85 pages\n",
    "        print(f'Scraping page {page}')\n",
    "        links = get_data_center_links(page)  # get all data centres on the current page\n",
    "        for i, link in enumerate(links):\n",
    "            print(f'    link {i}')\n",
    "            data_center_url = f'https://www.datacenters.com{link}'\n",
    "            data_center_info = extract_data_center_info(data_center_url)  # extract individual data\n",
    "            data_centers.append(data_center_info)\n",
    "            time.sleep(1)  # to prevent overwhelming the server with requests\n",
    "    df = pd.DataFrame(data_centers)  # convert to dataframe\n",
    "    df.to_csv('data/data_centers.csv', index=False)  # output to csv\n",
    "\n",
    "if __name__ == '__main__':  # run the main script\n",
    "    data_centers = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding data\n",
    "Now that the data is scraped and in csv format, the address must be geocoded to get latitude and longitude values which can then be plotted on a geographical plot. Geocoding can be done with the free geocode.maps API (though at a limited rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/data_centers.csv', sep=',')  # read in the data\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)  # remove useless column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the addresses first\n",
    "df['country'] = df['country'].str.strip().str.lower()  # remove whitespace and convert to lower case\n",
    "df['country'] = df['country'].replace('u.s.', 'usa')  # consistent naming\n",
    "df['country'] = df['country'].replace('united kingdom', 'uk')\n",
    "df.dropna(subset=['country'], inplace=True)  # remove blanks\n",
    "pattern = r'^[a-zA-Z\\s]+$'  # match all english alphabetic characters (including spaces)\n",
    "df_cleaned = df[df['country'].str.contains(pattern, na=False)]  # filter by above regex\n",
    "df_cleaned['country'] = df_cleaned['country'].str.replace(r'\\bU\\.S\\.?\\b', 'USA', regex=True)  # replace inconsistent USA naming\n",
    "df_cleaned = df_cleaned[~df_cleaned['country'].str.contains(r'[0-9一-龯]', na=False)]  # filter out non matching characters\n",
    "df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def geocode(location: str, index: int, df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    Geocode address and store lat and lon values in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        location (str): address to geocode.\n",
    "        index (int): position to store geocoded data in the dataframe.\n",
    "        df (pd.DataFrame): dataframe in which to store the data.\n",
    "    '''\n",
    "    url = f'https://geocode.maps.co/search?q={location}&api_key=668d02c6d9de4757313352qgufc7ba3'\n",
    "    response = requests.get(url)  # geocode by sending get request to API containing address\n",
    "    if response.status_code == 200 and response.json():  # successful get\n",
    "        print(response.json()[0])\n",
    "        df.loc[index, 'latitude'] = float(response.json()[0]['lat'])  # store in dataframe\n",
    "        df.loc[index, 'longitude'] = float(response.json()[0]['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "df['latitude'] = np.nan  # initialise the lat and lon columns as nan\n",
    "df['longitude'] = np.nan\n",
    "\n",
    "for index in range(len(df)):\n",
    "    try:\n",
    "        location: str = f'{df.loc[index, \"city\"]}, {df.loc[index, \"country\"]}'  # format the address for the API\n",
    "    except:\n",
    "        continue\n",
    "    geocode(location, index)\n",
    "    time.sleep(1.5)  # geocode at a limited rate\n",
    "\n",
    "df.to_csv('data/geo_data_centers_cleaned.csv')  # save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "Now the data has been cleaned and geocoded, visualisation can begin.\n",
    "This will be done using plotly and its associated dashboard library dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv('data/geo_data_centers_cleaned.csv', sep=',')  # read in csv data\n",
    "\n",
    "data.drop(columns=['Unnamed: 0.1'], inplace=True)  # remove useless columns\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data: pd.DataFrame = data[data['latitude'].notna() & data['longitude'].notna()]  # drop data centres that were not geocoded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3131/365771192.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  location_data['total power (MW)'] = location_data['total power (MW)'].apply(clean_total_power)  # clean the power column by applying the above function\n"
     ]
    }
   ],
   "source": [
    "def clean_total_power(value) -> float:\n",
    "    '''\n",
    "    Convert the power column to float values.\n",
    "\n",
    "    Args:\n",
    "        value (np.nan | str | float): power value to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        float: the power value converted to a float\n",
    "    '''\n",
    "    if pd.isna(value):  # nan values are set to zero\n",
    "        return 0.0\n",
    "    if isinstance(value, str):  # remove erroneous data bits\n",
    "        value = value.replace('MW', '').strip()\n",
    "    try:\n",
    "        value = float(value)  # convert to float\n",
    "        if value > 1000000:  # account for incorrect units\n",
    "            value /= 1000000\n",
    "        elif value > 100:\n",
    "            value /= 1000\n",
    "        return value\n",
    "    except ValueError:\n",
    "        return 0.0  # set to zero if exception occurs\n",
    "\n",
    "location_data['total power (MW)'] = location_data['total power (MW)'].apply(clean_total_power)  # clean the power column by applying the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=['https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css', 'styles.css'])  # create dash application and reference bootstrap layout style sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3131/4288146231.py:1: UserWarning:\n",
      "\n",
      "\n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "\n",
      "/tmp/ipykernel_3131/4288146231.py:2: UserWarning:\n",
      "\n",
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9b531b21a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "from dash import dcc, html\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from dash.dependencies import Input, Output\n",
    "from pandas.core.groupby.generic import DataFrameGroupBy\n",
    "\n",
    "BACKGROUND = '#121212'  # constant for background colour\n",
    "\n",
    "app.layout = html.Div(className='main-container', children=[  # create the app layout with html and css styling (under assets directory)\n",
    "    html.Div(className='top-row', children=[  # top row contains descriptive paragraph and map plot\n",
    "        html.Div(className='col-5', children=[  # descriptive paragraph\n",
    "            html.H1('Visualising Global Data Centres'),  # visualisation title\n",
    "            html.P(  # description\n",
    "                '''\n",
    "                Data centres play a vital but largely unseen role in everyday\n",
    "                internet activity. This dashboard explores where these centres\n",
    "                are located, who owns them, and how large they are.\n",
    "                '''\n",
    "            ),\n",
    "            html.P(\n",
    "                '''\n",
    "                *Note, some data (particularly related to China) is not openly\n",
    "                available. Keep this in consideration during comparisons.\n",
    "                '''\n",
    "            ),\n",
    "            html.P('''Use the drop down to filter all graphs and compare by country or by owning company.\n",
    "                   Use the range slider to filter based on the number of data centres owned.'''),\n",
    "            html.Div(className='compare-widget-container', children=[  # comparison dropdown and slider widgets container\n",
    "                html.Div(className='compare-by', children=[  # dropdown widget container\n",
    "                    html.Label(className='compare-widget-label', children='Compare by:'),  # dropdown widget label\n",
    "                    dcc.Dropdown(className='compare-widget', id='compare-filter', options=[  # dropdown widget\n",
    "                        {'label': html.Span(className='drop-text', children='Country'), 'value': 'COUNTRY'},  # selectable options\n",
    "                        {'label': html.Span(className='drop-text', children='Company'), 'value': 'COMPANY'},\n",
    "                    ], value='COUNTRY', searchable=False, clearable=False),  # cannot be searched or cleared (there must be a selected option)\n",
    "                ]),\n",
    "                html.Div(className='adjust-minimum', children=[  # slider widget container\n",
    "                    html.Label(className='slider-label', children='# Centres:'),  # slider widget label\n",
    "                    dcc.RangeSlider(min=0.99, max=(max_ := 8), step=None, marks={i: str(2 ** i) for i in range(max_ + 1)}, value=[4, 8], id='minimum-slider', className='slider-widget'),\n",
    "                ]),  # slider widget that range from 1 to 11 but is represented by powers of 2 for filtering\n",
    "            ]),\n",
    "        ]),\n",
    "        html.Div(className='col-7', children=[  # map graph column\n",
    "            html.H2('Geographical Distribution of Data Centres'),  # map graph heading\n",
    "            html.Div(className='map-widget-container', children=[  # map graph container\n",
    "                dcc.Graph(className='map-container', id='map-graph'),  # map graph\n",
    "                html.Div(className='map-widget', children=[  # map widget container\n",
    "                    html.Label(className='map-label', children='Filter by Power'),  # map widget label\n",
    "                    dcc.Checklist(className='checklist-container', id='power-filter', options=[  # map widget\n",
    "                        {'label': html.Span(className='check-text', children='Power Known'), 'value': 'WITH_POWER'},  # selectable options\n",
    "                        {'label': html.Span(className='check-text', children='Power Unknown'), 'value': 'WITHOUT_POWER'},\n",
    "                    ], value=['WITH_POWER']),  # default to data centres with power data available\n",
    "                    html.P(className='map-description', children=\n",
    "                           '''\n",
    "                           Explore data centre locations on this interactive globe with sizes\n",
    "                           proportionate to power consumption (where known).\n",
    "                           '''\n",
    "                    ),  # map description\n",
    "                ]),\n",
    "            ])\n",
    "        ]),\n",
    "    ]),\n",
    "    html.Div(className='bottom-row', children=[  # bottom row contains three interactive comparison plots\n",
    "        html.Div(className='compare-container', children=[  # row of plots container\n",
    "            html.Div(className='plot1', children=[  # lollipop graph container\n",
    "                html.H3('Data Centre Quantity'),  # plot heading\n",
    "                dcc.Graph(className='quantity-container', id='quantity-graph'),  # lollipop graph\n",
    "                html.P(className='plot-description', children=\n",
    "                       '''\n",
    "                       Compare the number of data centres located in a specific country or\n",
    "                       owned by a certain company.\n",
    "                       '''\n",
    "                ),  # plot description\n",
    "            ]),\n",
    "            html.Div(className='plot2', children=[  # box plot container\n",
    "                html.H3('Data Centre Size'),  # plot heading\n",
    "                dcc.Graph(className='size-container', id='size-graph'),  # box plot\n",
    "                html.P(className='plot-description', children=\n",
    "                       '''\n",
    "                       Compare the average and spread of data centre sizes located in a specific\n",
    "                       country or owned by a certain company.\n",
    "                       '''\n",
    "                ),\n",
    "            ]),\n",
    "            html.Div(className='plot3', children=[\n",
    "                html.H3('Data Centre Power'),\n",
    "                dcc.Graph(className='power-container', id='power-graph'),  # pie chart\n",
    "                html.P(className='plot-description', children=\n",
    "                       '''\n",
    "                       Compare the proportion of total power that data centres located in a\n",
    "                       specific country or owned by a certain company account for. Shares of < 2% have \n",
    "                       been accumulated into the \"other\" column.\n",
    "                       '''\n",
    "                ),\n",
    "            ]),\n",
    "        ]),\n",
    "    ])\n",
    "])\n",
    "\n",
    "def world_plot(lon: list, lat: list, text: list, marker: dict) -> go.Figure:\n",
    "    '''\n",
    "    Create the map figure.\n",
    "\n",
    "    Args:\n",
    "        lon (list): longitude values to plot.\n",
    "        lat (list): latitude values to plot.\n",
    "        text (list): additional hover information to plot.\n",
    "        marker (dict): marker display information (what size to plot the points).\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the map figure.\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scattergeo(lon=lon, lat=lat, text=text, marker=marker))  # plot the points\n",
    "    fig.update_layout(\n",
    "        geo=dict(\n",
    "            showland=True, landcolor=BACKGROUND,  # set map attributes and colours\n",
    "            showocean=True, oceancolor='grey',\n",
    "            showlakes=True, lakecolor='grey',\n",
    "            bgcolor=BACKGROUND, # set background colour\n",
    "            projection=dict(\n",
    "                type='orthographic',  # globe type\n",
    "                rotation=dict(lon=-100, lat=40)  # default lon and lat\n",
    "            ),\n",
    "            scope='world', showcountries=True,\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),  # remove outer whitespace\n",
    "        paper_bgcolor=BACKGROUND,  # set outer plot background colour\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "@app.callback(  # callback to update map based on checklist selection\n",
    "    Output('map-graph', 'figure'),  # outputs to map plot\n",
    "    [Input('power-filter', 'value'), Input('compare-filter', 'value'), Input('minimum-slider', 'value')],\n",
    ")  # takes the power filter, comparison filter, and range slider values in to produce the plot\n",
    "def update_map(power: list, owner: str, num: list) -> go.Figure:\n",
    "    '''\n",
    "    Redraw the map depending on which data is selected for plotting by the user.\n",
    "\n",
    "    Args:\n",
    "        power (list): list of strings representing power widget selection.\n",
    "        owner (str): text representing comparison widget selection.\n",
    "        num (list): list of values representing range slider selection.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the map figure.\n",
    "    '''\n",
    "    if max(num) == 8:  # if range slider is at the max value\n",
    "        num[num.index(max(num))] = 2048  # extend the maximum to include all values\n",
    "\n",
    "    if owner == 'COUNTRY':\n",
    "        key = 'country'\n",
    "    else:\n",
    "        key = 'name'\n",
    "    counts = location_data[key].value_counts()  # entry counts by key\n",
    "    filtered = counts[(counts > 2 ** min(num)) & (counts < 2 ** max(num))].index  # all entries within the slider range\n",
    "    filtered_data = location_data[location_data[key].isin(filtered)]  # filtered data according to slider range\n",
    "\n",
    "    if power == ['WITH_POWER']:  # power widget selection\n",
    "        filtered_data: pd.DataFrame = filtered_data[filtered_data['total power (MW)'] > 0]  # entries with power values\n",
    "    elif power == ['WITHOUT_POWER']:\n",
    "        filtered_data = filtered_data[filtered_data['total power (MW)'] == 0]  # entries without power values\n",
    "    elif len(power) == 2:  # both selected\n",
    "        filtered_data = filtered_data\n",
    "    else:  # none selected\n",
    "        return world_plot(lon=[0], lat=[0], text=[''], marker={'size': [0.5]})  # clear the plot\n",
    "\n",
    "    # Constant size for centres without power data, proportional for those with power data.\n",
    "    sizes: pd.Series = filtered_data['total power (MW)'].apply(lambda x: 7 if x == 0 else x / 3)\n",
    "    # Blue for centres without power data, red for those with power data.\n",
    "    colours: list = ['blue' if x == 0 else 'red' for x in filtered_data['total power (MW)']]\n",
    "\n",
    "    return world_plot(\n",
    "        lon=filtered_data['longitude'],\n",
    "        lat=filtered_data['latitude'],\n",
    "        text=filtered_data.apply(\n",
    "            lambda row: f\"Power: {row['total power (MW)']} MW<br>Colocation Space: {row['colocation space (sqft)']} sqft<br>Total Space: {row['total space (sqft)']} sqft\",\n",
    "            axis=1,\n",
    "        ),\n",
    "        marker=dict(\n",
    "            size=sizes,\n",
    "            color=colours,\n",
    "            line=dict(width=0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def create_lollipop(data: DataFrameGroupBy, filter: str, min_: int, max_: int) -> go.Figure:\n",
    "    '''\n",
    "    Create the lollipop graph (custom as not supported by plotly).\n",
    "\n",
    "    Args:\n",
    "        data (DataFrameGroupBy): data grouped by filter.\n",
    "        filter (str): text xaxis label.\n",
    "        min_ (int): minimum number of data centres to filter by.\n",
    "        max_ (int): maximum number of data centres to filter by.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the lollipop graph.\n",
    "    '''\n",
    "    if max_ == 256:\n",
    "        max_ = 2048  # set the max to go above the range slider and show top values\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(  # create a scatter trace of the data points initially\n",
    "            x=[a[0] for a in data if len(a[1]) > min_ and len(a[1]) < max_],  # strings for xaxis\n",
    "            y=[len(a[1]) for a in data if len(a[1]) > min_ and len(a[1]) < max_],  # data values (counts of data centres) for yaxis\n",
    "            mode='markers', marker=dict(color='red'), fillcolor=BACKGROUND\n",
    "    ))\n",
    "    shapes: list = []\n",
    "    i = 0\n",
    "    for _, group in data:  # iterate through the groups and create an appropriate line\n",
    "        if len(group) > min_ and len(group) < max_:\n",
    "            shapes.append(  # create the lines for the lollipop diagram\n",
    "                dict(type='line', xref='x', yref='y', x0=i, y0=0.9, x1=i, y1=len(group), line=dict(color='#fff', width=1))\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "    fig.update_layout(\n",
    "        shapes=shapes,  # add the line shapes with the scatter plot to create the custom lollipop diagram\n",
    "        xaxis=dict(type='category', color='#fff', title=filter), yaxis=dict(type='log', color='#fff', title='Number'),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        paper_bgcolor=BACKGROUND,\n",
    "        plot_bgcolor=BACKGROUND,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(  # customise plot formatting\n",
    "        gridcolor=BACKGROUND,  # hide grid lines\n",
    "        showline=True,  # show axis line\n",
    "        ticks='outside',  # show axis ticks\n",
    "        title_font=dict(size=20),  # set font attributes\n",
    "        tickfont=dict(size=15),\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        gridcolor=BACKGROUND,\n",
    "        ticks='outside',\n",
    "        title_font=dict(size=20),\n",
    "        tickfont=dict(size=15),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output('quantity-graph', 'figure'),  # outputs to lollipop graph\n",
    "    [Input('compare-filter', 'value'), Input('minimum-slider', 'value')],\n",
    ")  # takes comparison filter and slider range in to produce the plot\n",
    "def update_quantity(filter: str, num: list) -> go.Figure:\n",
    "    '''\n",
    "    Redraw the quantity lollipop chart depending on which comparison category is selected.\n",
    "\n",
    "    Args:\n",
    "        filter (str): text representing comparison widget selection.\n",
    "        num (list): list of values representing range slider selection.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the custom lollipop graph.\n",
    "    '''\n",
    "    if filter == 'COUNTRY':\n",
    "        filtered_data = location_data.groupby('country')\n",
    "        return create_lollipop(data=filtered_data, filter='Country', min_=2 ** min(num), max_=2 ** max(num))\n",
    "    else:\n",
    "        filtered_data = location_data.groupby('name')\n",
    "        return create_lollipop(data=filtered_data, filter='Company', min_=2 ** min(num), max_=2 ** max(num))\n",
    "\n",
    "def create_box(data: DataFrameGroupBy, filter: str, min_: int, max_: int) -> go.Figure:\n",
    "    '''\n",
    "    Create the go.Box plot.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrameGroupBy): data grouped by filter.\n",
    "        filter (str): text xaxis label.\n",
    "        min_ (int): minimum number of data centres to filter by.\n",
    "        max_ (int): maximum number of data centres to filter by.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the box plot.\n",
    "    '''\n",
    "    if max_ == 256:\n",
    "        max_ = 2048  # extend the range as above\n",
    "    traces: list = []\n",
    "    colours = px.colors.qualitative.Plotly  # select plotly's qualitative contrasting colours for colour blind accessibility\n",
    "    for i, (key, group) in enumerate(data):\n",
    "        if len(y := group['total space (sqft)']) > min_ and len(y := group['total space (sqft)']) < max_:  # filter within slider range\n",
    "            traces.append(go.Box(  # plot each box plot\n",
    "                name=key, y=y,\n",
    "                marker=dict(color=colours[i % len(colours)])\n",
    "            ))\n",
    "\n",
    "    layout = go.Layout(  # customise box plot layoutd\n",
    "        xaxis=dict(title=filter, title_font=dict(size=20), tickfont=dict(size=15)),\n",
    "        yaxis=dict(title='Size (sqft)', title_font=dict(size=20), tickfont=dict(size=15), type='log'),\n",
    "        template='plotly_dark',\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "    )\n",
    "\n",
    "    return go.Figure(data=traces, layout=layout)\n",
    "\n",
    "@app.callback(\n",
    "    Output('size-graph', 'figure'),  # outputs to box plot\n",
    "    [Input('compare-filter', 'value'), Input('minimum-slider', 'value')],\n",
    ")  # takes comparison filter and slider range in to produce the plot\n",
    "def update_size(filter: str, num: list) -> go.Figure:\n",
    "    '''\n",
    "    Redraw the box plots depending on which comparison category is selected.\n",
    "\n",
    "    Args:\n",
    "        filter (str): text representing comparison widget selection.\n",
    "        num (list): list of values representing range slider selection.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the box plot.\n",
    "    '''\n",
    "    if filter == 'COUNTRY':\n",
    "        filtered_data = location_data.groupby('country')\n",
    "        return create_box(data=filtered_data, filter='Country', min_=2 ** min(num), max_=2 ** max(num))\n",
    "    else:\n",
    "        filtered_data = location_data.groupby('name')\n",
    "        return create_box(data=filtered_data, filter='Company', min_=2 ** min(num), max_=2 ** max(num))\n",
    "\n",
    "def create_pie(data: DataFrameGroupBy, val_col: str, lab_col: str) -> go.Figure:\n",
    "    '''\n",
    "    Create the pie chart.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrameGroupBy): data grouped by filter.\n",
    "        val_col (str): data column of interest in the grouped data object.\n",
    "        lab_col (str): label column of interest in the grouped data object.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the pie chart.\n",
    "    '''\n",
    "    total: float = data[val_col].sum()  # pie chart total\n",
    "    data['percentage'] = data[val_col] / total  # calculate percentage shares\n",
    "    large: pd.DataFrame = data[data['percentage'] >= 0.02]  # include if >= 2% share\n",
    "    small: pd.DataFrame = data[data['percentage'] < 0.02]  # otherwise exclude\n",
    "    other: float = small[val_col].sum()  # accumulate < 2% shares\n",
    "    if other > 0:\n",
    "        large = pd.concat([large, pd.DataFrame({lab_col: ['Other'], val_col: [other], 'percentage': [other / total]})])  # add 'other' column\n",
    "\n",
    "    pie_data = go.Pie(  # create pie chart\n",
    "        labels=large[lab_col],\n",
    "        values=large[val_col],\n",
    "        textinfo='label+percent',  # show labels and percentage share values\n",
    "        insidetextorientation='radial',  # display text radially in chart\n",
    "        hoverinfo='label+percent+value',\n",
    "        marker=dict(\n",
    "            colors=px.colors.qualitative.Plotly,  # use Plotly's qualitative color palette\n",
    "            line=dict(color='#121212', width=2)  # white borders with width 2\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(  # customise layout\n",
    "        template='plotly_dark',\n",
    "        legend=dict(  # text attributes for legend\n",
    "            title=dict(text=lab_col.capitalize(), font=dict(size=16)),\n",
    "            x=1, y=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return go.Figure(data=[pie_data], layout=layout)\n",
    "\n",
    "@app.callback(\n",
    "    Output('power-graph', 'figure'),  # output to pie chart.\n",
    "    [Input('compare-filter', 'value'), Input('minimum-slider', 'value')]\n",
    ")  # takes comparison filter and slider range in to produce the plot\n",
    "def update_power(filter, num) -> go.Figure:\n",
    "    '''\n",
    "    Redraw the pie chart depending on which comparsion category is selected.\n",
    "\n",
    "    Args:\n",
    "        filter (str): text representing comparison widget selection.\n",
    "        num (list): list of values representing range slider selection.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: the pie chart.\n",
    "    '''\n",
    "    if max(num) == 8:\n",
    "        num[num.index(max(num))] = 11\n",
    "    if filter == 'COUNTRY':\n",
    "        key = 'country'\n",
    "    else:\n",
    "        key = 'name'\n",
    "    datacenter_counts = location_data[key].value_counts()  # entry counts by key\n",
    "    filtered = datacenter_counts[(datacenter_counts > 2 ** min(num)) & (datacenter_counts < 2 ** max(num))].index  # all entries within slider range\n",
    "    filtered_data = location_data[location_data[key].isin(filtered)]  # filter by slider range\n",
    "    grouped_data = filtered_data.groupby(key)['total power (MW)'].sum().reset_index()  # group by key and sum power values\n",
    "    return create_pie(grouped_data, 'total power (MW)', key)\n",
    "\n",
    "app.run_server(debug=True)  # run the server to display the dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
